1. Two Pointer









2.Fast and Slow Pointer












3. Sliding Window









4. Prefix Sum










Checking if the number is even or odd without using the % operator: 
Although this trick is not much better than using a % operator but is sometimes efficient (with large numbers). 

Use & operator:

System.out.println((a & 1) == 0 ?  "EVEN" : "ODD" );
Example: 

num = 5 
Binary: "101 & 1" will be 001, so false 

num = 4 
Binary: "100 & 1" will be 000, so true.




Fast Multiplication or Division by 2 

Multiplying by 2 means shifting all the bits to left and dividing by 2 means shifting to the right.

Example: 2 (Binary 10): shifting left 4 (Binary 100) and right 1 (Binary 1)

n = n << 1;   // Multiply n with 2
n = n >> 1;   // Divide n by 2




Swapping of 2 numbers using XOR: 

This method is fast and doesnâ€™t require the use of the 3rd variable.

  // A quick way to swap a and b
  a ^= b;
  b ^= a;
  a ^= b;




Calculating the most significant digit: 

To calculate the most significant digit of any number log can be directly used to calculate it. 

Suppose the number is N then 
Let double K = Math.log10(N);
now K = K - Math.floor(K);
int X = (int)Math.pow(10, K);
X will be the most significant digit. 




Calculating the number of digits directly:

To calculate the number of digits in a number, instead of looping we can efficiently use log : 

No. of digits in N = Math.floor(Math.log10(N)) + 1;





Java has inbuilt GCD method in BigInteger class. It returns a BigInteger whose value is the greatest common divisor of abs(this) and abs(val).
Returns 0 if this==0 && val==0. 

Syntax : 

public BigInteger gcd(BigInteger val)
Parameters :
val - value with which the GCD is to be computed.
Returns :
GCD(abs(this), abs(val))


// Java program to demonstrate how 
// to use gcd method of BigInteger class 

import java.math.BigInteger; 

class Test { 
	public static int gcd(int a, int b) 
	{ 
		BigInteger b1 = BigInteger.valueOf(a); 
		BigInteger b2 = BigInteger.valueOf(b); 
		BigInteger gcd = b1.gcd(b2); 
		return gcd.intValue(); 
	} 

	public static long gcd(long a, long b) 
	{ 
		BigInteger b1 = BigInteger.valueOf(a); 
		BigInteger b2 = BigInteger.valueOf(b); 
		BigInteger gcd = b1.gcd(b2); 
		return gcd.longValue(); 
	} 

	// Driver method 
	public static void main(String[] args) 
	{ 
		System.out.println(gcd(3, 5)); 
		System.out.println(gcd(10000000000L, 600000000L)); 
	} 
}





Efficient trick to know if a number is a power of 2:

The normal technique of division the complexity comes out to be O(logN), but it can be solved using O(v) where v is the number of digits of the number in binary form.  

/* Method to check if x is power of 2*/
static boolean isPowerOfTwo (int x) 
{ 
     /* First x in the below expression is  
     for the case when x is 0 */
      return x!=0 && ((x&(x-1)) == 0);     
} 



1. Dynamic Programming:
Dynamic programming is a method for solving complex problems by breaking them down into simpler subproblems and solving each subproblem only once, storing the results to avoid redundant computations.
Applications:
Fibonacci Sequence: Computing the nth Fibonacci number efficiently using dynamic programming to avoid recalculating overlapping subproblems.
Shortest Path Problems: Finding the shortest path in a graph, such as the Floyd-Warshall algorithm or Dijkstra's algorithm.
Knapsack Problem: Finding the maximum value of items that can be accommodated into a knapsack of limited capacity.
Longest Common Subsequence (LCS): Finding the longest subsequence common to two sequences.

2. Greedy Algorithms:
Greedy algorithms make locally optimal choices at each step with the hope of finding a global optimum, without reconsidering previous choices.
Applications:
Minimum Spanning Tree (MST): Constructing a minimum spanning tree in a graph using algorithms like Kruskal's or Prim's algorithm.
Dijkstra's Algorithm: Finding the shortest path in a weighted graph with non-negative weights.
Huffman Coding: Constructing an optimal prefix-free binary encoding of characters based on their frequencies.
Interval Scheduling: Selecting a maximum-size subset of mutually compatible activities from a set of activities that share resources.

2. Backtracking:
Backtracking is a method for systematically searching through all possible solutions to a problem by recursively trying different choices and backtracking when a dead-end is reached.
Applications:
N-Queens Problem: Placing N queens on an NxN chessboard such that no two queens attack each other.
Sudoku Solver: Solving a partially filled Sudoku grid by backtracking to find a valid solution.
Subset Sum: Finding if there exists a subset of a given set with a given sum.
Hamiltonian Cycle: Finding a Hamiltonian cycle in a graph, if it exists.

4. Divide and Conquer:
Divide and Conquer is a technique that involves breaking down a problem into smaller subproblems, solving each subproblem independently, and then combining their solutions to solve the original problem.
Applications:
Binary Search: Searching for an element in a sorted array by repeatedly dividing the search interval in half.
Merge Sort: Sorting an array by recursively dividing it into two halves, sorting the halves, and then merging them.
Closest Pair of Points: Finding the pair of points with the smallest distance among a set of points in a plane.
Strassen's Algorithm: Multiplying two matrices efficiently using recursive matrix multiplication.

5. Branch and Bound:
Branch and Bound is a method for solving optimization problems by systematically searching the solution space, pruning branches that are not promising and bounding the search to find the optimal solution.
Applications:
Traveling Salesman Problem (TSP): Finding the shortest possible route that visits each city exactly once and returns to the origin city.
Integer Linear Programming: Solving optimization problems where the objective function and constraints are linear, with integer-valued variables.

6. Randomized Algorithms:
Randomized Algorithms use randomness to improve the efficiency or correctness of algorithms, often by introducing probabilistic choices or random sampling.
Applications:
Randomized QuickSort: Sorting elements by partitioning them around a randomly chosen pivot, improving the average-case time complexity of QuickSort.
Randomized Primality Testing: Determining whether a given number is prime with high probability using probabilistic algorithms like Miller-Rabin primality test.
Monte Carlo Simulation: Estimating numerical results or solving problems through repeated random sampling, such as estimating the value of pi or simulating complex systems.

7. Graph Algorithms:
Graph Algorithms focus on solving problems related to graphs, such as traversal, shortest paths, connectivity, and network flows.
Applications:
Topological Sorting: Ordering the vertices of a directed acyclic graph (DAG) such that for every directed edge uv, vertex u comes before vertex v in the ordering.
Strongly Connected Components (SCC): Decomposing a directed graph into its strongly connected components using algorithms like Kosaraju's or Tarjan's algorithm.
Network Flow Problems: Finding the maximum flow from a source to a sink in a flow network, such as the Ford-Fulkerson algorithm or Edmonds-Karp algorithm.

8. String Matching Algorithms:
String Matching Algorithms are used to find occurrences of a substring within a larger string or to search for patterns within text.
Applications:
Knuth-Morris-Pratt (KMP) Algorithm: Efficiently searching for occurrences of a pattern within a text string by avoiding unnecessary character comparisons.
Rabin-Karp Algorithm: Searching for a substring within a text string by hashing substrings and comparing their hashes for equality.
Suffix Tree and Suffix Array: Data structures for storing all suffixes of a string and efficiently searching for patterns in the string.
